{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alimi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pydub\\utils.py:165: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os.path import isfile,join\n",
    "from os import listdir\n",
    "from scipy import signal as sg\n",
    "from scipy.signal import butter,lfilter,freqz\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import hamming\n",
    "import soundfile as sf\n",
    "import scipy\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import logfbank\n",
    "import librosa\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "import math\n",
    "import tensorflow\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_yaml\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras import backend\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers import Conv2D,Conv1D,MaxPooling1D,GlobalAveragePooling1D,GlobalMaxPooling1D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten,Dropout\n",
    "from keras import optimizers, callbacks\n",
    "import numpy as np\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator,img_to_array\n",
    "#from sklearn.preprocessing import StandardbScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/Users/User/100baby_cry/370CRY'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6d803244b908>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbabycry\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/User/100baby_cry/370CRY'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/User/100baby_cry/370CRY'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbabysilence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/User/baby/baby_cry/901 - Silence'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/User/baby/baby_cry/901 - Silence'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbabynoise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/User/baby/baby_cry/902 - Noise'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/User/baby/baby_cry/902 - Noise'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbabylaugh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/User/baby/baby_cry/903 - Baby laugh'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/User/baby/baby_cry/903 - Baby laugh'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/Users/User/100baby_cry/370CRY'"
     ]
    }
   ],
   "source": [
    "babycry=[f for f in listdir('/Users/User/100baby_cry/370CRY') if isfile(join('/Users/User/100baby_cry/370CRY', f))]\n",
    "\n",
    "babysilence=[f for f in listdir('/Users/User/baby/baby_cry/901 - Silence') if isfile(join('/Users/User/baby/baby_cry/901 - Silence', f))]\n",
    "babynoise=[f for f in listdir('/Users/User/baby/baby_cry/902 - Noise') if isfile(join('/Users/User/baby/baby_cry/902 - Noise', f))]\n",
    "babylaugh=[f for f in listdir('/Users/User/baby/baby_cry/903 - Baby laugh') if isfile(join('/Users/User/baby/baby_cry/903 - Baby laugh', f))]\n",
    "babynew=[f for f in listdir('/Users/User/baby/audio') if isfile(join('/Users/User/baby/audio', f))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_cry=[]\n",
    "for each in range(0,len(babycry)) :\n",
    "    cry='/Users/User/100baby_cry/370CRY' + '/' + babycry[each] \n",
    "    baby_cry.append(cry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_silence=[]\n",
    "for each in range(0,len(babysilence)) :\n",
    "    silence='/Users/User/baby/baby_cry/901 - Silence' + '/' + babysilence[each] \n",
    "    baby_silence.append(silence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_noise=[]\n",
    "for each in range(0,len(babynoise)) :\n",
    "    noise='/Users/User/baby/baby_cry/902 - Noise' + '/' + babynoise[each] \n",
    "    baby_silence.append(noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_laugh=[]\n",
    "for each in range(0,len(babylaugh)) :\n",
    "    laugh='/Users/User/baby/baby_cry/903 - Baby laugh' + '/' + babylaugh[each] \n",
    "    baby_laugh.append(laugh)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_new=[]\n",
    "for each in range(0,len(babynew)) :\n",
    "    unknown='/Users/User/baby/audio' + '/' + babynew[each] \n",
    "    baby_new.append(unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbabycry = baby_silence + baby_noise + baby_laugh + baby_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nonbabycry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(baby_cry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[1,4,6,8,9,10,2,4,5]\n",
    "#x=np.array(x)\n",
    "np.array_split(x,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass(cutoff,fs,order=5):\n",
    "    nyq=0.5*fs\n",
    "    normal_cutoff=cutoff/nyq\n",
    "    b,a=butter(order,normal_cutoff,btype='low',analog=False)\n",
    "    return b,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass_filter(data,cutoff,fs,order=5):\n",
    "    b,a=butter_lowpass(cutoff,fs,order=order)\n",
    "    y=lfilter(b,a,data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(soundfile):\n",
    "    s,r=sf.read(soundfile)\n",
    "    s=butter_lowpass_filter(s,11025,44100,order=3)\n",
    "    x=np.array_split(s,64)\n",
    "    print(x)\n",
    "    \n",
    "    logg=[]\n",
    "    for i in x:\n",
    "             \n",
    "             xx=np.mean(logfbank(i,r,nfilt=40,nfft=1103),axis=0)\n",
    "             logg.append(xx)\n",
    "        \n",
    "    return  logg  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=feature(baby_cry[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#j=np.mean(r,axis=0)\n",
    "np.shape(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(\"deep.csv\",r,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.zeros((669,64,40))\n",
    "output=[]\n",
    "for i in range(0,len(baby_cry)):\n",
    "       #print(baby_cry[i])\n",
    "       r=feature(baby_cry[i])\n",
    "       \n",
    "       #r=list(r)\n",
    "       data[i,:,:]=r\n",
    "       output.append(1) \n",
    "        \n",
    "all=baby_cry+nonbabycry\n",
    "for i in range(len(baby_cry)-1,len(all)-1):\n",
    "       #r=list(r)\n",
    "      # print(all[i]) \n",
    "       r=feature(all[i])\n",
    "       \n",
    "       data[i,:,:]=r\n",
    "       output.append(0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = baby_cry[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, output, test_size=0.30, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Reshape, Flatten, Dropout, Concatenate, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(64, 2, activation='relu', input_shape=(64, 40)))\n",
    "model.add(Conv1D(40,2,padding='valid', activation='relu',strides=1))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(40))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization(epsilon=0.001, mode=0, momentum=0.9, weights=None))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, nb_epoch=1000, validation_split=0.3,batch_size=10, shuffle=False,verbose=2)\n",
    "#model.fit(data,output, epochs=10000, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test, y_pred.round()))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ncnn1.json','w') as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"ncnn1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat=feature('201104291843.wav')\n",
    "d=np.zeros((32,40))\n",
    "for i in range(len(feat)):\n",
    "    d[i,:]=feat[i]\n",
    "X=np.expand_dims(d,axis=0)    \n",
    "model.predict_classes(X)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
